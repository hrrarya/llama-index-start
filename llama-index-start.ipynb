{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07104bd-b837-461b-be77-2fe32bb63088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (0.14.12)\n",
      "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index) (0.5.3)\n",
      "Requirement already satisfied: llama-index-core<0.15.0,>=0.14.12 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index) (0.14.12)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index) (0.5.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index) (0.9.4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index) (0.6.12)\n",
      "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index) (0.5.6)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index) (0.5.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index) (3.9.2)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (3.13.3)\n",
      "Requirement already satisfied: aiosqlite in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (0.22.1)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (2025.12.0)\n",
      "Requirement already satisfied: httpx in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (2.11.7)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (3.6.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (2.4.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (12.1.0)\n",
      "Requirement already satisfied: platformdirs in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (4.5.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (2.12.5)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.12->llama-index) (2.0.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (1.22.0)\n",
      "Requirement already satisfied: griffe in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.1.6)\n",
      "Requirement already satisfied: openai>=1.1.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (2.14.0)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.14.3)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
      "Requirement already satisfied: pandas<3,>=2.0.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.3.3)\n",
      "Requirement already satisfied: pypdf<7,>=6.1.3 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (6.5.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8.1)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.12->llama-index) (0.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (3.11)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.12->llama-index) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.12->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.12->llama-index) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (0.4.2)\n",
      "Requirement already satisfied: llama-cloud==0.1.35 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.54 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: click<9,>=8.1.7 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.3.1)\n",
      "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.2.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (2025.11.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.26.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15.0,>=0.14.12->llama-index) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9dfedef-12c1-4515-976c-2157a439450d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (2.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from openai) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a8cd3e0-a239-4c02-8c29-c266ff372798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4c39393-1f52-48dd-bd09-08e55621261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-ollama\n",
      "  Downloading llama_index_llms_ollama-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: llama-index-core<0.15,>=0.14.5 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-llms-ollama) (0.14.12)\n",
      "Collecting ollama>=0.5.3 (from llama-index-llms-ollama)\n",
      "  Downloading ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (3.13.3)\n",
      "Requirement already satisfied: aiosqlite in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (0.22.1)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (2025.12.0)\n",
      "Requirement already satisfied: httpx in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (2.11.7)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (3.6.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (3.9.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (2.4.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (12.1.0)\n",
      "Requirement already satisfied: platformdirs in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (4.5.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (2.12.5)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (2.0.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (1.22.0)\n",
      "Requirement already satisfied: griffe in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (0.4.2)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (3.11)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (8.3.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (2025.11.3)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (4.12.1)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (3.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (3.26.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-ollama) (3.0.3)\n",
      "Downloading llama_index_llms_ollama-0.9.1-py3-none-any.whl (8.7 kB)\n",
      "Downloading ollama-0.6.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: ollama, llama-index-llms-ollama\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [llama-index-llms-ollama]\n",
      "\u001b[1A\u001b[2KSuccessfully installed llama-index-llms-ollama-0.9.1 ollama-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-llms-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70e0e6a7-485a-41ba-8ebd-2bf08063a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "# from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.deepseek import DeepSeek\n",
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "092c4f49-9467-4b11-82a8-eef9e1c749ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2845523b-434f-4412-82fe-5acb51d31157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a:float, b:float)->float:\n",
    "    return a*b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a62bcc4-a8cf-4ba8-9e95-262e81da97bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product of 1250 and 1500 is 1875000.\n"
     ]
    }
   ],
   "source": [
    "deepseek_api_key=\"sk-dde1a868d256432d9cdab54de8c2da38\"\n",
    "agent=FunctionAgent(\n",
    "    tools=[multiply],\n",
    "    llm=Ollama(model=\"qwen2.5:3b\", base_url=\"http://localhost:11434\"),\n",
    "    system_prompt=\"you are a helpfull asistant that can multiply two numbers.\"\n",
    ")\n",
    "response = await agent.run(\"what is 1250*1500\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06960b62-3fdf-47a1-98fa-7a2949e42f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = Context(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d9f557b-f518-49f3-993e-f24bedd6d468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Hridoy. How can I assist you further? Do you need help multiplying two numbers or do you have any other questions?\n"
     ]
    }
   ],
   "source": [
    "response = await agent.run(\"my name is hridoy\", ctx=context)\n",
    "response = await agent.run(\"what is my name?\", ctx=context)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb38526-e34e-475f-8731-11fca26d0c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca005111-9e67-4c88-afb8-378ec1a5becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple RAG Application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3490c312-c523-4497-b82f-c82f49a6bea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee02781c-a9d3-4d45-b075-fa840c678472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 23:54:54,594 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:54:54,597 - INFO - Retrying request to /embeddings in 0.432374 seconds\n",
      "2026-01-07 23:54:55,415 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:54:55,417 - INFO - Retrying request to /embeddings in 0.831869 seconds\n",
      "2026-01-07 23:54:56,541 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:54:56,544 - INFO - Retrying request to /embeddings in 1.983526 seconds\n",
      "2026-01-07 23:54:58,998 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:54:58,999 - INFO - Retrying request to /embeddings in 3.136922 seconds\n",
      "2026-01-07 23:55:02,480 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:55:02,482 - INFO - Retrying request to /embeddings in 6.598328 seconds\n",
      "2026-01-07 23:55:09,443 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:55:09,444 - INFO - Retrying request to /embeddings in 7.103591 seconds\n",
      "2026-01-07 23:55:16,868 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:55:16,870 - INFO - Retrying request to /embeddings in 6.186046 seconds\n",
      "2026-01-07 23:55:23,880 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:55:23,882 - INFO - Retrying request to /embeddings in 6.125106 seconds\n",
      "2026-01-07 23:55:30,333 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:55:30,334 - INFO - Retrying request to /embeddings in 7.332065 seconds\n",
      "2026-01-07 23:55:37,951 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:55:37,953 - INFO - Retrying request to /embeddings in 6.228953 seconds\n",
      "2026-01-07 23:55:44,565 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:55:44,569 - WARNING - Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings in 1.0 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.\n",
      "2026-01-07 23:55:45,999 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:55:46,004 - INFO - Retrying request to /embeddings in 0.482659 seconds\n",
      "2026-01-07 23:55:46,754 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:55:46,756 - INFO - Retrying request to /embeddings in 0.763992 seconds\n",
      "2026-01-07 23:55:47,842 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:55:47,844 - INFO - Retrying request to /embeddings in 1.726072 seconds\n",
      "2026-01-07 23:55:49,890 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:55:49,891 - INFO - Retrying request to /embeddings in 3.921223 seconds\n",
      "2026-01-07 23:55:54,191 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:55:54,193 - INFO - Retrying request to /embeddings in 6.193145 seconds\n",
      "2026-01-07 23:56:00,745 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:56:00,747 - INFO - Retrying request to /embeddings in 6.821770 seconds\n",
      "2026-01-07 23:56:08,220 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:56:08,221 - INFO - Retrying request to /embeddings in 6.139106 seconds\n",
      "2026-01-07 23:56:14,670 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:56:14,671 - INFO - Retrying request to /embeddings in 7.873496 seconds\n",
      "2026-01-07 23:56:22,863 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:56:22,866 - INFO - Retrying request to /embeddings in 7.812382 seconds\n",
      "2026-01-07 23:56:31,003 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-07 23:56:31,004 - INFO - Retrying request to /embeddings in 6.345162 seconds\n",
      "2026-01-07 23:56:37,710 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m documents = SimpleDirectoryReader(\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m).load_data()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m index = \u001b[43mVectorStoreIndex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m query_engine = index.as_query_engine()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/base.py:122\u001b[39m, in \u001b[36mBaseIndex.from_documents\u001b[39m\u001b[34m(cls, documents, storage_context, show_progress, callback_manager, transformations, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m     docstore.set_document_hash(doc.id_, doc.hash)\n\u001b[32m    115\u001b[39m nodes = run_transformations(\n\u001b[32m    116\u001b[39m     documents,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    117\u001b[39m     transformations,\n\u001b[32m    118\u001b[39m     show_progress=show_progress,\n\u001b[32m    119\u001b[39m     **kwargs,\n\u001b[32m    120\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:75\u001b[39m, in \u001b[36mVectorStoreIndex.__init__\u001b[39m\u001b[34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28mself\u001b[39m._embed_model = resolve_embed_model(\n\u001b[32m     71\u001b[39m     embed_model \u001b[38;5;129;01mor\u001b[39;00m Settings.embed_model, callback_manager=callback_manager\n\u001b[32m     72\u001b[39m )\n\u001b[32m     74\u001b[39m \u001b[38;5;28mself\u001b[39m._insert_batch_size = insert_batch_size\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/base.py:79\u001b[39m, in \u001b[36mBaseIndex.__init__\u001b[39m\u001b[34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m     nodes = nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     index_struct = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28mself\u001b[39m._index_struct = index_struct\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m._storage_context.index_store.add_index_struct(\u001b[38;5;28mself\u001b[39m._index_struct)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:309\u001b[39m, in \u001b[36mVectorStoreIndex.build_index_from_nodes\u001b[39m\u001b[34m(self, nodes, **insert_kwargs)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(content_nodes) != \u001b[38;5;28mlen\u001b[39m(nodes):\n\u001b[32m    307\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSome nodes are missing content, skipping them...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:278\u001b[39m, in \u001b[36mVectorStoreIndex._build_index_from_nodes\u001b[39m\u001b[34m(self, nodes, **insert_kwargs)\u001b[39m\n\u001b[32m    276\u001b[39m     run_async_tasks(tasks)\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_add_nodes_to_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_show_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:231\u001b[39m, in \u001b[36mVectorStoreIndex._add_nodes_to_index\u001b[39m\u001b[34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[39m\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nodes_batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(nodes, \u001b[38;5;28mself\u001b[39m._insert_batch_size):\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     nodes_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_node_with_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m     new_ids = \u001b[38;5;28mself\u001b[39m._vector_store.add(nodes_batch, **insert_kwargs)\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._vector_store.stores_text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._store_nodes_override:\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[32m    236\u001b[39m         \u001b[38;5;66;03m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:138\u001b[39m, in \u001b[36mVectorStoreIndex._get_node_with_embedding\u001b[39m\u001b[34m(self, nodes, show_progress)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_node_with_embedding\u001b[39m(\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    128\u001b[39m     nodes: Sequence[BaseNode],\n\u001b[32m    129\u001b[39m     show_progress: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    130\u001b[39m ) -> List[BaseNode]:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Get tuples of id, node, and embedding.\u001b[39;00m\n\u001b[32m    133\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    136\u001b[39m \n\u001b[32m    137\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     id_to_embed_map = \u001b[43membed_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m     results = []\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/utils.py:177\u001b[39m, in \u001b[36membed_nodes\u001b[39m\u001b[34m(nodes, embed_model, show_progress)\u001b[39m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    175\u001b[39m         id_to_embed_map[node.node_id] = node.embedding\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m new_embeddings = \u001b[43membed_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_text_embedding_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts_to_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m new_id, text_embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ids_to_embed, new_embeddings):\n\u001b[32m    182\u001b[39m     id_to_embed_map[new_id] = text_embedding\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/base/embeddings/base.py:473\u001b[39m, in \u001b[36mBaseEmbedding.get_text_embedding_batch\u001b[39m\u001b[34m(self, texts, show_progress, **kwargs)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    469\u001b[39m     CBEventType.EMBEDDING,\n\u001b[32m    470\u001b[39m     payload={EventPayload.SERIALIZED: \u001b[38;5;28mself\u001b[39m.to_dict()},\n\u001b[32m    471\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embeddings_cache:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m         embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_text_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embeddings_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    475\u001b[39m         embeddings = \u001b[38;5;28mself\u001b[39m._get_text_embeddings_cached(cur_batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/embeddings/openai/base.py:472\u001b[39m, in \u001b[36mOpenAIEmbedding._get_text_embeddings\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_retryable_get_embeddings\u001b[39m():\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_embeddings(\n\u001b[32m    466\u001b[39m         client,\n\u001b[32m    467\u001b[39m         texts,\n\u001b[32m    468\u001b[39m         engine=\u001b[38;5;28mself\u001b[39m._text_engine,\n\u001b[32m    469\u001b[39m         **\u001b[38;5;28mself\u001b[39m.additional_kwargs,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retryable_get_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/embeddings/openai/base.py:465\u001b[39m, in \u001b[36mOpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_retryable_get_embeddings\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_text_engine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madditional_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/embeddings/openai/base.py:172\u001b[39m, in \u001b[36mget_embeddings\u001b[39m\u001b[34m(client, list_of_text, engine, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(list_of_text) <= \u001b[32m2048\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mThe batch size should not be larger than 2048.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m list_of_text = [text.replace(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m list_of_text]\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m data = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mlist_of_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.data\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [d.embedding \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/openai/resources/embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12836ab7-1065-406a-abaa-772845f9a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 00:03:32,427 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:03:32,429 - INFO - Retrying request to /embeddings in 0.467693 seconds\n",
      "2026-01-08 00:03:33,245 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:03:33,246 - INFO - Retrying request to /embeddings in 0.817415 seconds\n",
      "2026-01-08 00:03:34,476 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:03:34,477 - INFO - Retrying request to /embeddings in 1.882776 seconds\n",
      "2026-01-08 00:03:37,412 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:03:37,414 - INFO - Retrying request to /embeddings in 3.615970 seconds\n",
      "2026-01-08 00:03:41,437 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:03:41,438 - INFO - Retrying request to /embeddings in 6.643570 seconds\n",
      "2026-01-08 00:03:48,503 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:03:48,505 - INFO - Retrying request to /embeddings in 6.809754 seconds\n",
      "2026-01-08 00:03:55,885 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:03:55,887 - INFO - Retrying request to /embeddings in 6.571460 seconds\n",
      "2026-01-08 00:04:02,826 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:04:02,827 - INFO - Retrying request to /embeddings in 6.480790 seconds\n",
      "2026-01-08 00:04:09,681 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:04:09,683 - INFO - Retrying request to /embeddings in 7.437899 seconds\n",
      "2026-01-08 00:04:17,481 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:04:17,483 - INFO - Retrying request to /embeddings in 6.376660 seconds\n",
      "2026-01-08 00:04:24,243 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:04:24,246 - WARNING - Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings in 1.0 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.\n",
      "2026-01-08 00:04:25,672 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:04:25,673 - INFO - Retrying request to /embeddings in 0.428314 seconds\n",
      "2026-01-08 00:04:26,492 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:04:26,495 - INFO - Retrying request to /embeddings in 0.964985 seconds\n",
      "2026-01-08 00:04:27,823 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:04:27,825 - INFO - Retrying request to /embeddings in 1.600120 seconds\n",
      "2026-01-08 00:04:29,769 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:04:29,770 - INFO - Retrying request to /embeddings in 3.177423 seconds\n",
      "2026-01-08 00:04:33,252 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:04:33,253 - INFO - Retrying request to /embeddings in 7.223390 seconds\n",
      "2026-01-08 00:04:41,032 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:04:41,034 - INFO - Retrying request to /embeddings in 7.406900 seconds\n",
      "2026-01-08 00:04:48,916 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:04:48,917 - INFO - Retrying request to /embeddings in 7.184209 seconds\n",
      "2026-01-08 00:04:56,700 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:04:56,701 - INFO - Retrying request to /embeddings in 7.423081 seconds\n",
      "2026-01-08 00:05:04,483 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:05:04,484 - INFO - Retrying request to /embeddings in 7.467730 seconds\n",
      "2026-01-08 00:05:12,367 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n",
      "2026-01-08 00:05:12,369 - INFO - Retrying request to /embeddings in 6.625661 seconds\n",
      "2026-01-08 00:05:19,433 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m documents = SimpleDirectoryReader(\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m).load_data()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m index = \u001b[43mVectorStoreIndex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m query_engine = index.as_query_engine()\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msearch_query\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m)->\u001b[38;5;28mstr\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/base.py:122\u001b[39m, in \u001b[36mBaseIndex.from_documents\u001b[39m\u001b[34m(cls, documents, storage_context, show_progress, callback_manager, transformations, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m     docstore.set_document_hash(doc.id_, doc.hash)\n\u001b[32m    115\u001b[39m nodes = run_transformations(\n\u001b[32m    116\u001b[39m     documents,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    117\u001b[39m     transformations,\n\u001b[32m    118\u001b[39m     show_progress=show_progress,\n\u001b[32m    119\u001b[39m     **kwargs,\n\u001b[32m    120\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:75\u001b[39m, in \u001b[36mVectorStoreIndex.__init__\u001b[39m\u001b[34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28mself\u001b[39m._embed_model = resolve_embed_model(\n\u001b[32m     71\u001b[39m     embed_model \u001b[38;5;129;01mor\u001b[39;00m Settings.embed_model, callback_manager=callback_manager\n\u001b[32m     72\u001b[39m )\n\u001b[32m     74\u001b[39m \u001b[38;5;28mself\u001b[39m._insert_batch_size = insert_batch_size\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/base.py:79\u001b[39m, in \u001b[36mBaseIndex.__init__\u001b[39m\u001b[34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m     nodes = nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     index_struct = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28mself\u001b[39m._index_struct = index_struct\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m._storage_context.index_store.add_index_struct(\u001b[38;5;28mself\u001b[39m._index_struct)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:309\u001b[39m, in \u001b[36mVectorStoreIndex.build_index_from_nodes\u001b[39m\u001b[34m(self, nodes, **insert_kwargs)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(content_nodes) != \u001b[38;5;28mlen\u001b[39m(nodes):\n\u001b[32m    307\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSome nodes are missing content, skipping them...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:278\u001b[39m, in \u001b[36mVectorStoreIndex._build_index_from_nodes\u001b[39m\u001b[34m(self, nodes, **insert_kwargs)\u001b[39m\n\u001b[32m    276\u001b[39m     run_async_tasks(tasks)\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_add_nodes_to_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_show_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:231\u001b[39m, in \u001b[36mVectorStoreIndex._add_nodes_to_index\u001b[39m\u001b[34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[39m\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nodes_batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(nodes, \u001b[38;5;28mself\u001b[39m._insert_batch_size):\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     nodes_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_node_with_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m     new_ids = \u001b[38;5;28mself\u001b[39m._vector_store.add(nodes_batch, **insert_kwargs)\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._vector_store.stores_text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._store_nodes_override:\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[32m    236\u001b[39m         \u001b[38;5;66;03m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:138\u001b[39m, in \u001b[36mVectorStoreIndex._get_node_with_embedding\u001b[39m\u001b[34m(self, nodes, show_progress)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_node_with_embedding\u001b[39m(\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    128\u001b[39m     nodes: Sequence[BaseNode],\n\u001b[32m    129\u001b[39m     show_progress: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    130\u001b[39m ) -> List[BaseNode]:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Get tuples of id, node, and embedding.\u001b[39;00m\n\u001b[32m    133\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    136\u001b[39m \n\u001b[32m    137\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     id_to_embed_map = \u001b[43membed_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m     results = []\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/indices/utils.py:177\u001b[39m, in \u001b[36membed_nodes\u001b[39m\u001b[34m(nodes, embed_model, show_progress)\u001b[39m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    175\u001b[39m         id_to_embed_map[node.node_id] = node.embedding\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m new_embeddings = \u001b[43membed_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_text_embedding_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts_to_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m new_id, text_embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ids_to_embed, new_embeddings):\n\u001b[32m    182\u001b[39m     id_to_embed_map[new_id] = text_embedding\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/core/base/embeddings/base.py:473\u001b[39m, in \u001b[36mBaseEmbedding.get_text_embedding_batch\u001b[39m\u001b[34m(self, texts, show_progress, **kwargs)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    469\u001b[39m     CBEventType.EMBEDDING,\n\u001b[32m    470\u001b[39m     payload={EventPayload.SERIALIZED: \u001b[38;5;28mself\u001b[39m.to_dict()},\n\u001b[32m    471\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embeddings_cache:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m         embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_text_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embeddings_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    475\u001b[39m         embeddings = \u001b[38;5;28mself\u001b[39m._get_text_embeddings_cached(cur_batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/embeddings/openai/base.py:472\u001b[39m, in \u001b[36mOpenAIEmbedding._get_text_embeddings\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_retryable_get_embeddings\u001b[39m():\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_embeddings(\n\u001b[32m    466\u001b[39m         client,\n\u001b[32m    467\u001b[39m         texts,\n\u001b[32m    468\u001b[39m         engine=\u001b[38;5;28mself\u001b[39m._text_engine,\n\u001b[32m    469\u001b[39m         **\u001b[38;5;28mself\u001b[39m.additional_kwargs,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retryable_get_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/embeddings/openai/base.py:465\u001b[39m, in \u001b[36mOpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_retryable_get_embeddings\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_text_engine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madditional_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/llama_index/embeddings/openai/base.py:172\u001b[39m, in \u001b[36mget_embeddings\u001b[39m\u001b[34m(client, list_of_text, engine, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(list_of_text) <= \u001b[32m2048\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mThe batch size should not be larger than 2048.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m list_of_text = [text.replace(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m list_of_text]\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m data = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mlist_of_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.data\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [d.embedding \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/openai/resources/embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llama-index-start/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "async def search_query(query: str)->str:\n",
    "    response = query_engine.aquery(query)\n",
    "    return str(response)\n",
    "\n",
    "agent = FunctionAgent(\n",
    "    tools=[search_query],\n",
    "    llm=Ollama(model=\"qwen2.5:3b\", base_url=\"http://localhost:11434\"),\n",
    "    system_prompt=\"You are a helpfull asistant that can search through documents to answer the questions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4770e4-93aa-4226-99a9-8fc13e7d3535",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent.run(\"what did the author in college?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883da7c4-29ac-40c7-9ea2-33823edfb42a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
